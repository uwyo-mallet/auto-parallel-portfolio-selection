ignoreTimeoutsOnVBS = FALSE,
orderBy = "pred+aSE", a = a)
summary = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = FALSE,
orderBy = "pred+aSE")
summary_med = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = TRUE,
orderBy = "pred+aSE")
resR = rbind(resR, summary[[1]])
resMCP = rbind(resMCP, summary[[2]])
resPar10 = rbind(resPar10, summary[[3]])
resR_m = rbind(resR_m,summary_med[[1]])
resMCP_m = rbind(resMCP_m,summary_med[[2]])
resPar10_m = rbind(resPar10_m,summary_med[[3]])
}
summary = list(resR, resMCP, resPar10, resR_m, resMCP_m, resPar10_m)
} else {
for(c in range){
path_to_schedule = paste("/home/haniye/Documents/OrganizedScripts/results/MAXSAT2019/time_splitting/pred+SE/",c,"_cores/",sep="")
summary = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = FALSE,
orderBy = "pred+aSE")
summary_med = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = TRUE,
orderBy = "pred+aSE")
resR = rbind(resR, summary[[1]])
resMCP = rbind(resMCP, summary[[2]])
resPar10 = rbind(resPar10, summary[[3]])
resR_m = rbind(resR_m,summary_med[[1]])
resMCP_m = rbind(resMCP_m,summary_med[[2]])
resPar10_m = rbind(resPar10_m,summary_med[[3]])
}
summary = list(resR, resMCP, resPar10, resR_m, resMCP_m, resPar10_m)
}
return(summary)
}
get_time_splitting_cutoff = function(saved = TRUE){
# AS sequential time spliting
self = PredictionResults$new("MAXSAT2019")
range = c(1:self$sequentialData$n_solvers)
resR = data.frame(matrix(ncol= 11,nrow=0))
resMCP = data.frame(matrix(ncol= 11,nrow=0))
resPar10 = data.frame(matrix(ncol= 11,nrow=0))
resR_m = data.frame(matrix(ncol= 11,nrow=0))
resMCP_m = data.frame(matrix(ncol= 11,nrow=0))
resPar10_m = data.frame(matrix(ncol= 11,nrow=0))
if(!saved){
for(c in range){
path_to_schedule = paste("/home/haniye/Documents/OrganizedScripts/results/MAXSAT2019/time_splitting/cutoff/",c,"_cores/",sep="")
self$time_splitting_scheduling(predictionPath = self$predictionPath,
selectionPath = path_to_schedule,
cores = c,
ignoreTimeoutsOnVBS = FALSE,
orderBy = "cutoff")
summary = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = FALSE,
orderBy = "cutoff")
summary_med = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = TRUE,
orderBy = "cutoff")
resR = rbind(resR, summary[[1]])
resMCP = rbind(resMCP, summary[[2]])
resPar10 = rbind(resPar10, summary[[3]])
resR_m = rbind(resR_m,summary_med[[1]])
resMCP_m = rbind(resMCP_m,summary_med[[2]])
resPar10_m = rbind(resPar10_m,summary_med[[3]])
}
summary = list(resR, resMCP, resPar10, resR_m, resMCP_m, resPar10_m)
} else {
for(c in range){
path_to_schedule = paste("/home/haniye/Documents/OrganizedScripts/results/MAXSAT2019/time_splitting/",c,"_cores/",sep="")
summary = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = FALSE,
orderBy = "pred")
summary_med = self$time_splitting_scheduling_scraper(selectionPath = path_to_schedule,
ignoreTimeouts = FALSE,
median = TRUE,
orderBy = "pred")
resR = rbind(resR, summary[[1]])
resMCP = rbind(resMCP, summary[[2]])
resPar10 = rbind(resPar10, summary[[3]])
resR_m = rbind(resR_m,summary_med[[1]])
resMCP_m = rbind(resMCP_m,summary_med[[2]])
resPar10_m = rbind(resPar10_m,summary_med[[3]])
}
summary = list(resR, resMCP, resPar10, resR_m, resMCP_m, resPar10_m)
}
return(summary)
}
get_flexfolio_3s_results = function(){
self = PredictionResults$new("MAXSAT2019")
range = c(1:self$sequentialData$n_solvers)
resR = data.frame(matrix(ncol= 6,nrow=0))
resR_m = data.frame(matrix(ncol= 6,nrow=0))
for(c in range){
path_to_results = paste("/home/haniye/Documents/PortfolioScheduling/Baselines/flexfolio/MAXSAT2019/maxsat_results/MAXSAT-",
c,"core-3s.csv",sep="")
csv = read.csv(path_to_results)
csv$par10 = csv$claspfolio
csv$claspfolio[which(csv$claspfolio == 36000)] <- 3600
csv= csv[order(csv$Instance),]
vbs = get_top_vbs()[1:2]
csv$vbs = vbs$cores_1
csv$mcp = csv$claspfolio - csv$vbs
resR = rbind(resR, c(mean(csv$vbs), mean(csv$claspfolio), mean(csv$mcp), mean(csv$par10),c, "FALSE"))
colnames(resR) <- c("vbs", "runtime", "mcp", "par10","cores", "median")
resR_m = rbind(resR_m, c(median(csv$vbs), median(csv$claspfolio), median(csv$mcp), median(csv$par10),c, "TRUE"))
colnames(resR_m) <- c("vbs", "runtime", "mcp", "par10","cores", "median")
}
summary = list(resR, resR_m)
return(summary)
}
get_joint_probability_optimum = function(){
self = PredictionResults$new("MAXSAT2019")
range = seq(0,1,by=0.001)
min = Inf
optimum = Inf
range = range[1:1001]
for(r in range){
dir.create(paste("~/Documents/OrganizedScripts/results/MAXSAT2019/JointProbability/tau_",r,sep = ""))
self$selection_based_on_SE(predictionPath = self$predictionPath,
saveTo = paste("~/Documents/OrganizedScripts/results/MAXSAT2019/JointProbability/tau_",r,sep=""),
method_number = 5,
top_selection = 10,
ignoreTimeoutsOnVBS = FALSE,
orderBy = "pred",
delta = 0,
delta_prime = 0,
alpha = 0,
JP_limit = r)
summary = self$get_summary_selection_result( paste("~/Documents/OrganizedScripts/results/MAXSAT2019/JointProbability/tau_",r,sep=""),
ignoreTimeouts = FALSE,
method_number = 5,
median = FALSE)
print(r)
print(summary)
if(as.numeric(summary[[1]]$Parallel_time)<=min){
min = as.numeric(summary[[1]]$Parallel_time)
optimum = r
}
}
return(optimum)
}
get_joint_probability_results = function(saved = TRUE, optimum = 0.549){
self = PredictionResults$new("MAXSAT2019")
range = c(1:self$sequentialData$n_solvers)
resR = data.frame(matrix(ncol= 11,nrow=0))
resMCP = data.frame(matrix(ncol= 11,nrow=0))
resPar10 = data.frame(matrix(ncol= 11,nrow=0))
resR_m = data.frame(matrix(ncol= 11,nrow=0))
resMCP_m = data.frame(matrix(ncol= 11,nrow=0))
resPar10_m = data.frame(matrix(ncol= 11,nrow=0))
if(!saved){
for(i in range){
self$selection_based_on_SE(predictionPath = self$predictionPath,
saveTo = paste("~/Documents/OrganizedScripts/results/MAXSAT2019/joint_optimal/",i, "-core",sep=""),
method_number = 5,
top_selection = i,
ignoreTimeoutsOnVBS = FALSE,
orderBy = "pred",
delta = 0,
delta_prime = 0,
alpha = 0,
JP_limit = optimum)
summary = self$get_summary_selection_result(paste("~/Documents/OrganizedScripts/results/MAXSAT2019/joint_optimal/",i,"-core",sep=""),
ignoreTimeouts = FALSE,
method_number = 5,
median = FALSE)
summary_med = self$get_summary_selection_result(paste("~/Documents/OrganizedScripts/results/MAXSAT2019/joint_optimal/",i,"-core",sep=""),
ignoreTimeouts = FALSE,
method_number = 5,
median = TRUE)
resR = rbind(resR, summary[[1]])
resMCP = rbind(resMCP, summary[[2]])
resPar10 = rbind(resPar10, summary[[3]])
resR_m = rbind(resR_m,summary_med[[1]])
resMCP_m = rbind(resMCP_m,summary_med[[2]])
resPar10_m = rbind(resPar10_m,summary_med[[3]])
}
} else{
for(i in range){
summary = self$get_summary_selection_result(paste("~/Documents/OrganizedScripts/results/MAXSAT2019/joint_optimal/",i,"-core",sep=""),
ignoreTimeouts = FALSE,
method_number = 5,
median = FALSE)
summary_med = self$get_summary_selection_result(paste("~/Documents/OrganizedScripts/results/MAXSAT2019/joint_optimal/",i,"-core",sep=""),
ignoreTimeouts = FALSE,
method_number = 5,
median = TRUE)
resR = rbind(resR, summary[[1]])
resMCP = rbind(resMCP, summary[[2]])
resPar10 = rbind(resPar10, summary[[3]])
resR_m = rbind(resR_m,summary_med[[1]])
resMCP_m = rbind(resMCP_m,summary_med[[2]])
resPar10_m = rbind(resPar10_m,summary_med[[3]])
}
}
summary = list(resR, resMCP, resPar10, resR_m, resMCP_m, resPar10_m)
return(summary)
}
get_optimum_tau = function(){
# theta = read.csv("~/Documents/OrganizedScripts/results/MAXSAT2019//RandomSearch_MAXSAT2019_combined_allEqual_NOTignoreTO_300.csv")
# theta = theta[which(theta$metric=="Runtime"),]
# theta = theta[which(theta$median==FALSE),]
# plot(x = theta$delta, y = theta$Parallel_time)
# #best =  0.1116461, runtime = 110.3998
# theta = theta[which(theta$Parallel_time == min(theta$Parallel_time)),]
# theta = theta$delta[1]
# range =c(1:7)
# theta = 0.0625
# selectionPath = "~/Documents/OrganizedScripts/results/MAXSAT2019/selections_optimal_theta_0.0625/selection_optimal_theta_7_cores/"
# self = PredictionResults$new("MAXSAT2019")
# summary = self$get_summary_all(method_numbers = 3,top_selections = 7, predictionPath = self$predictionPath,
# selectionPath = selectionPath, ignoreTimeoutsOnVBS = FALSE, median = FALSE,
# delta = theta, alpha = theta, delta_prime = theta)
#
# write.arff(summary,"~/Documents/OrganizedScripts/results/MAXSAT2019/top_Uncertainty_Theta_0.1098642_limitingSolvers.arff")
}
plot_vbs_stats = function(save=FALSE){
top_vbs = get_top_vbs()
top_vbs[2:8] = apply(top_vbs[2:8],2,as.numeric)
sd = apply(top_vbs[2:8],2,sd)
mean = apply(top_vbs[2:8],2,mean)
median = apply(top_vbs[2:8],2,median)
sum_top_vbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_vbs$cores = c(1:7)
sum_top_vbs = sum_top_vbs[which(!(sum_top_vbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_vbs, aes(x=cores, y=mean,colour="Mean VBS Runtime")) +
geom_point()+
geom_point(aes(y=median,colour="Median VBS Runtime"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "Runtime"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
if(save){
ggsave(dpi = 500, width = 7, height = 5, filename = "VBS_behavior_different_cores_runtime.pdf")
}
return(p)
}
plot_sbs_stats = function(save=FALSE){
top_sbs = get_top_sbs()
top_sbs[2:8] = apply(top_sbs[2:8],2,as.numeric)
sd = apply(top_sbs[2:8],2,sd)
mean = apply(top_sbs[2:8],2,mean)
median = apply(top_sbs[2:8],2,median)
sum_top_sbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_sbs$cores = c(1:7)
sum_top_sbs = sum_top_sbs[which(!(sum_top_sbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_sbs, aes(x=cores, y=mean,colour="Mean SBS Runtime")) +
geom_point()+
geom_point(aes(y=median,colour="Median SBS Runtime"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "Runtime"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
if(save){
ggsave(filename = "SBS_behavior_different_cores_runtime.pdf",dpi = 500, width = 7, height = 5)
}
return(p)
}
plot_all_results = function(save = FALSE, optimum = 0.549, metric = "Runtime"){
results = scrape_all_results()
results[2:8] <- lapply(results[2:8],as.numeric)
optimum = 0.549
if(metric == "Runtime"){
p <- ggplot(results, aes(x=cores, y=Runtime, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(size = 1)+
# geom_line(aes(linetype="Mean"), size = 1)+
# geom_point(aes(y=Median),size = 3)+
# geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "Runtime (s)", title = "MAXSAT19-UCMS")+theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:7))+
scale_color_discrete(labels=c(bquote(AS[1]), 'Single Best Solver',
"Timesplitting_preds", "Timesplitting_preds+SE",
bquote(AS[~p[~'\u2229']]), 'Virtual Best Solver'))+
scale_shape_discrete(labels=c(bquote(AS[1]), 'Single Best Solver',
"Timesplitting_preds", "Timesplitting_preds+SE",
bquote(AS[~p[~'\u2229']]), 'Virtual Best Solver'))+
scale_y_continuous(trans='log10')
if(save){
ggsave(dpi = 500, width = 9, height = 5, filename = "MAXSAT19_line_chart_parallel_runtime.pdf")
}
} else if(metric == "MCP"){
p <- ggplot(results, aes(x=cores, y=MCP, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(size = 1)+
# geom_line(aes(linetype="Mean"), size = 1)+
# geom_point(aes(y=Median),size = 3)+
# geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "MCP", title = "MAXSAT19-UCMS")+theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:7))+
scale_color_discrete(labels=c(bquote(AS[1]), 'Single Best Solver',
"Timesplitting_preds", "Timesplitting_preds+SE",
bquote(AS[~p[~'\u2229']]), 'Virtual Best Solver'))+
scale_shape_discrete(labels=c(bquote(AS[1]), 'Single Best Solver',
"Timesplitting_preds", "Timesplitting_preds+SE",
bquote(AS[~p[~'\u2229']]), 'Virtual Best Solver'))+
scale_y_continuous(trans='log10')
if(save){
ggsave(dpi = 500, width = 9, height = 5, filename = "MAXSAT19_line_chart_parallel_MCP.pdf")
}
} else if(metric == "PAR10"){
p <- ggplot(results, aes(x=cores, y=PAR10, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(size = 1)+
# geom_line(aes(linetype="Mean"), size = 1)+
# geom_point(aes(y=Median),size = 3)+
# geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "PAR10", title = "MAXSAT19-UCMS")+theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:7))+
scale_color_discrete(labels=c(bquote(AS[1]), 'Single Best Solver',
"Timesplitting_preds", "Timesplitting_preds+SE",
bquote(AS[~p[~'\u2229']]), 'Virtual Best Solver'))+
scale_shape_discrete(labels=c(bquote(AS[1]), 'Single Best Solver',
"Timesplitting_preds", "Timesplitting_preds+SE",
bquote(AS[~p[~'\u2229']]), 'Virtual Best Solver'))+
scale_y_continuous(trans='log10')
if(save){
ggsave(dpi = 500, width = 9, height = 5, filename = "MAXSAT19_line_chart_parallel_PAR10.pdf")
}
}
return(p)
}
plot_all_results_normalized_gap = function(save = FALSE, optimum = 0.549){
#vbs is 1
#sbs is 0
#sbs-value/sbs-vbs
results = scrape_all_results()
results[2:8] <- lapply(results[2:8],as.numeric)
results = results[c(1,2,5,8)]
par10_sbs = get_top_sbs()$cores_1
par10_sbs[which(par10_sbs==3600)] <- 36000
par10_sbs = mean(par10_sbs)
par10_vbs = get_top_vbs()$cores_1
par10_vbs[which(par10_vbs==3600)] <- 36000
par10_vbs = mean(par10_vbs)
results$PAR10= (par10_sbs - results$PAR10)/(par10_sbs - par10_vbs)
results$PAR10 = as.numeric(results$PAR10)
p = ggplot(results, aes(x=cores, y=PAR10, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(size = 1)+
# geom_line(aes(linetype="Mean"), size = 1)+
# geom_point(aes(y=Median),size = 3)+
# geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Processors", y = "Normalized Gap Closed", title = "MAXSAT19-UCMS")+
theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:7))+
scale_color_discrete(labels=c("3S", bquote(AS[1]), 'SBS',
"Time Splitting", bquote(AS[~p[~'\u2229']]), 'VBS'))+
scale_shape_discrete(labels=c("3S", bquote(AS[1]), 'SBS',
"Time Splitting", bquote(AS[~p[~'\u2229']]), 'VBS'))
if(save){
ggsave(dpi = 500, width = 9, height = 5, filename = "MAXSAT19_line_chart_parallel_NormalizedGap.pdf")
}
return(p)
}
scrape_all_results = function(){
df_results = data.frame(matrix(nrow = 0, ncol = 9))
top_vbs = get_top_vbs()
for(c in colnames(top_vbs)[2:ncol(top_vbs)]){
top_vbs[c][[1]] <- as.numeric(unlist(top_vbs[c][[1]]))
if(c == "cores_1"){
par10 = top_vbs$cores_1
par10[which(par10==3600)] <- 36000
row = c("VBS", 1, mean(top_vbs$cores_1), 0, mean(par10), median(top_vbs$cores_1), 0, median(par10),"Sequential VBS, Oracle")
df_results= rbind(df_results,row)
colnames(df_results) = c("Approach", "cores", "Runtime", "MCP", "PAR10", "median_Runtime", "median_MCP", "median_PAR10","decription")
} else{
runtime = top_vbs[c][[1]]
par10 = runtime
par10[which(par10==3600)] = 36000
mcp = runtime - top_vbs$cores_1
row = c("VBS", str_split(c,"cores_")[[1]][2],
mean(runtime), mean(mcp), mean(par10),
median(runtime), median(mcp), median(par10),
paste("Parallel VBS,",c))
df_results= rbind(df_results,row)
}
}
top_sbs = get_top_sbs()
for(c in colnames(top_sbs)[2:ncol(top_sbs)]){
top_sbs[c][[1]] <- as.numeric(unlist(top_sbs[c][[1]]))
if(c == "cores_1"){
runtime = top_sbs[c][[1]]
par10 = top_sbs$cores_1
par10[which(par10==3600)] <- 36000
mcp = runtime - top_vbs$cores_1
row = c("SBS", 1, mean(top_sbs$cores_1), mean(mcp), mean(par10), median(top_sbs$cores_1), median(mcp),median(par10),"Sequential SBS")
df_results= rbind(df_results,row)
colnames(df_results) = c("Approach", "cores", "Runtime", "MCP", "PAR10", "median_Runtime", "median_MCP", "median_PAR10","decription")
} else{
runtime = top_sbs[c][[1]]
par10 = runtime
par10[which(par10==3600)] = 36000
mcp = runtime - top_vbs$cores_1
row = c("SBS", str_split(c,"cores_")[[1]][2],
mean(runtime), mean(mcp), mean(par10),
median(runtime), median(mcp), median(par10),
paste("Parallel SBS,",c))
df_results= rbind(df_results,row)
}
}
top_as = get_top_AS_noUncertainty_noSplitting()
for(c in 1:nrow(top_as[[1]])){
if(c == 1){
row = c("AS", 1, top_as[[1]][1,]$Parallel_time, top_as[[2]][1,]$Parallel_time, top_as[[3]][1,]$Parallel_time, top_as[[4]][1,]$Parallel_time, top_as[[5]][1,]$Parallel_time, top_as[[6]][1,]$Parallel_time,"Single Algorithm Selection")
df_results= rbind(df_results,row)
} else{
row = c("AS", c, top_as[[1]][c,]$Parallel_time, top_as[[2]][c,]$Parallel_time, top_as[[3]][c,]$Parallel_time,top_as[[4]][c,]$Parallel_time, top_as[[5]][c,]$Parallel_time, top_as[[6]][c,]$Parallel_time, "Algorithm Selection - Top, based on prediction, no uncertainty or time splitting")
df_results= rbind(df_results,row)
}
}
# time_splitting_pred = get_time_splitting_prediction()
# for(c in 1:nrow(time_splitting_pred[[1]])){
#   if(c == 1){
#     row = c("Time Splitting - Prediction", 1, time_splitting_pred[[1]][1,]$Schedule_time, time_splitting_pred[[2]][1,]$Schedule_time, time_splitting_pred[[3]][1,]$Schedule_time,
#             time_splitting_pred[[4]][1,]$Schedule_time, time_splitting_pred[[5]][1,]$Schedule_time, time_splitting_pred[[6]][1,]$Schedule_time, "Sequential Timesplitting based on Predictions")
#     df_results= rbind(df_results,row)
#   } else{
#     row = c("Time Splitting - Prediction", c, time_splitting_pred[[1]][c,]$Schedule_time, time_splitting_pred[[2]][c,]$Schedule_time, time_splitting_pred[[3]][c,]$Schedule_time,
#             time_splitting_pred[[4]][c,]$Schedule_time, time_splitting_pred[[5]][c,]$Schedule_time, time_splitting_pred[[6]][c,]$Schedule_time, "Parallel Timesplitting based on Predictions - Grid bin packing")
#     df_results= rbind(df_results,row)
#   }
# }
time_splitting_predSE = get_time_splitting_prediction_aSE(a = 1)
for(c in 1:nrow(time_splitting_predSE[[1]])){
if(c == 1){
row = c("Time Splitting - Prediction+SE", 1, time_splitting_predSE[[1]][1,]$Schedule_time, time_splitting_predSE[[2]][1,]$Schedule_time, time_splitting_predSE[[3]][1,]$Schedule_time,
time_splitting_predSE[[4]][1,]$Schedule_time, time_splitting_predSE[[5]][1,]$Schedule_time, time_splitting_predSE[[6]][1,]$Schedule_time,"Sequential Timesplitting based on Predictions+SE")
df_results= rbind(df_results,row)
} else{
row = c("Time Splitting - Prediction+SE", c, time_splitting_predSE[[1]][c,]$Schedule_time, time_splitting_predSE[[2]][c,]$Schedule_time, time_splitting_predSE[[3]][c,]$Schedule_time,
time_splitting_predSE[[4]][c,]$Schedule_time, time_splitting_predSE[[5]][c,]$Schedule_time, time_splitting_predSE[[6]][c,]$Schedule_time, "Parallel Timesplitting based on Predictions+SE - Grid bin packing")
df_results= rbind(df_results,row)
}
}
# time_splitting_predSE = get_time_splitting_prediction_aSE(a = 2)
# for(c in 1:nrow(time_splitting_predSE[[1]])){
#   if(c == 1){
#     row = c("Time Splitting - Prediction+2SE", 1, time_splitting_predSE[[1]][1,]$Schedule_time, time_splitting_predSE[[2]][1,]$Schedule_time, time_splitting_predSE[[3]][1,]$Schedule_time,
#             time_splitting_predSE[[4]][1,]$Schedule_time, time_splitting_predSE[[5]][1,]$Schedule_time, time_splitting_predSE[[6]][1,]$Schedule_time,"Sequential Timesplitting based on Predictions+SE")
#     df_results= rbind(df_results,row)
#   } else{
#     row = c("Time Splitting - Prediction+2SE", c, time_splitting_predSE[[1]][c,]$Schedule_time, time_splitting_predSE[[2]][c,]$Schedule_time, time_splitting_predSE[[3]][c,]$Schedule_time,
#             time_splitting_predSE[[4]][c,]$Schedule_time, time_splitting_predSE[[5]][c,]$Schedule_time, time_splitting_predSE[[6]][c,]$Schedule_time, "Parallel Timesplitting based on Predictions+SE - Grid bin packing")
#     df_results= rbind(df_results,row)
#   }
# }
# optimum = get_joint_probability_optimum()
optimum = 0.549
JoinProbabilityResults = get_joint_probability_results(optimum)
for(c in 1:nrow(JoinProbabilityResults[[1]])){
if(c == 1){
row = c("Uncertainty - JointProbability", 1, JoinProbabilityResults[[1]][1,]$Parallel_time, JoinProbabilityResults[[2]][1,]$Parallel_time, JoinProbabilityResults[[3]][1,]$Parallel_time,
JoinProbabilityResults[[4]][1,]$Parallel_time, JoinProbabilityResults[[5]][1,]$Parallel_time, JoinProbabilityResults[[6]][1,]$Parallel_time,"Uncertainty - JointProbability - optimum = 0.549")
df_results= rbind(df_results,row)
} else{
row = c("Uncertainty - JointProbability", c, JoinProbabilityResults[[1]][c,]$Parallel_time, JoinProbabilityResults[[2]][c,]$Parallel_time, JoinProbabilityResults[[3]][c,]$Parallel_time,
JoinProbabilityResults[[4]][c,]$Parallel_time, JoinProbabilityResults[[5]][c,]$Parallel_time, JoinProbabilityResults[[6]][c,]$Parallel_time, "Uncertainty - JointProbability - optimum = 0.549")
df_results= rbind(df_results,row)
}
}
flexfolio_3s = get_flexfolio_3s_results()
for(c in 1:nrow(flexfolio_3s[[1]])){
if(c == 1){
row = c("3S", 1, flexfolio_3s[[1]][1,]$runtime, flexfolio_3s[[1]][1,]$mcp, flexfolio_3s[[1]][1,]$par10,
flexfolio_3s[[2]][1,]$runtime, flexfolio_3s[[2]][1,]$mcp, flexfolio_3s[[2]][1,]$par10,"Flexfolio implemantation of 3S, using sequential scenarios")
df_results= rbind(df_results,row)
} else{
row = c("3S", c, flexfolio_3s[[1]][c,]$runtime, flexfolio_3s[[1]][c,]$mcp, flexfolio_3s[[1]][c,]$par10,
flexfolio_3s[[2]][c,]$runtime, flexfolio_3s[[2]][c,]$mcp, flexfolio_3s[[2]][c,]$par10,"Flexfolio implemantation of 3S, using parallel scenarios")
df_results= rbind(df_results,row)
}
}
return(df_results)
}
set_paths()
plot_vbs_stats(save = FALSE)
plot_sbs_stats(save = FALSE)
results = scrape_all_results()
setwd("../MAXSAT2019/")
write.csv(results,'summary_results_all.csv',row.names = FALSE)
results[which(results$cores == 7),]
p = plot_all_results_normalized_gap()
p
ggsave(dpi = 500, width = 9, height = 5, filename = "MAXSAT19_line_chart_parallel_NormalizedGap.pdf")
