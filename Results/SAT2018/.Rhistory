library(reshape2)
top_vbs = read.csv("top_vbs_par10.csv")
top_vbs[1:7] = apply(top_vbs[1:7],2,as.numeric)
sd = apply(top_vbs[1:7],2,sd)
mean = apply(top_vbs[1:7],2,mean)
median = apply(top_vbs[1:7],2,median)
sum_top_vbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_vbs$cores = c(1:7)
sum_top_vbs = sum_top_vbs[which(!(sum_top_vbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_vbs, aes(x=cores, y=mean,colour="Mean VBS PAR10")) +
geom_point()+
geom_point(aes(y=median,colour="Median VBS PAR10"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "PAR10"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
getwd()
ggsave(dpi = 500, width = 7, height = 5, filename = "VBS_behavior_different_cores_PAR10.pdf")
top_sbs = read.csv("top_sbs_par10.csv")
top_sbs[1:7] = apply(top_sbs[1:7],2,as.numeric)
sd = apply(top_sbs[1:7],2,sd)
mean = apply(top_sbs[1:7],2,mean)
median = apply(top_sbs[1:7],2,median)
sum_top_sbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_sbs$cores = c(1:7)
sum_top_sbs = sum_top_sbs[which(!(sum_top_sbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_sbs, aes(x=cores, y=mean,colour="Mean SBS PAR10")) +
geom_point()+
geom_point(aes(y=median,colour="Median SBS PAR10"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "PAR10"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
ggsave(filename = "SBS_behavior_different_cores_PAR10.pdf",dpi = 500, width = 7, height = 5)
results = data.frame(matrix(nrow= 0, ncol=4))
approaches = c("Single Best Solver", "Virtual Best Solver", "ASPEED",
"AS_0", "AS_theta")
for(approach in approaches){
sub_df = data.frame(matrix(nrow= 7, ncol=0))
sub_df$Cores = c(1:7)
sub_df$Approach = approach
if(approach == "Virtual Best Solver"){
sub_df$Mean = as.numeric(sum_top_vbs$mean)
sub_df$Median = as.numeric(sum_top_vbs$median)
} else if(approach == "Single Best Solver"){
sub_df$Mean = as.numeric(sum_top_sbs$mean)
sub_df$Median = as.numeric(sum_top_sbs$median)
} else if(approach == "ASPEED"){
aspeed = read.csv("top_aspeed_par10.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(aspeed)))
sub_df$Median = as.numeric(colMedians(as.matrix(aspeed)))
} else if(approach == "AS_0"){
as_0 = read.csv("top_as_0_par10.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(as_0)))
sub_df$Median = as.numeric(colMedians(as.matrix(as_0)))
} else if(approach == "AS_theta"){
as_0 = read.csv("top_as_theta_par10.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(as_0)))
sub_df$Median = as.numeric(colMedians(as.matrix(as_0)))
}
results = rbind(results,sub_df)
}
results$Mean = as.numeric(results$Mean)
results$Median = as.numeric(results$Median)
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=15,  family="Times"))+
labs(x = "Cores", y = "PAR10 (s)", title = "GRAPHS2015")+theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:7))
ggsave(dpi = 500, width = 9, height = 5, filename = "line_chart_parallel_PAR10.pdf")
ggsave(dpi = 500, width = 9, height = 5, filename = "GRAPHS15_line_chart_parallel_PAR10.pdf")
library(reshape2)
if(Sys.info()['sysname']=="Linux"){
if(file.exists("~/Documents/OrganizedScripts/OverheadResults.R")){
source("~/Documents/OrganizedScripts/OverheadResults.R")
Estimate_overhead_on_predictionPath ="~/Documents/OrganizedScripts/SAT2018/Estimate_overhead_on_prediction/"
actual_overhead_per_solverPlotPath = "~/Documents/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc/plot/"
actual_overhead_per_solverPath = "~/Documents/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc/"
actual_overhead_per_corePlotPath = "~/Documents/OrganizedScripts/SAT2018/actual_overhead_per_core_perc/plot/"
actual_overhead_per_corePath = "~/Documents/OrganizedScripts/SAT2018/actual_overhead_per_core_perc/"
#predictionPath = "~/Documents/OrganizedScripts/SAT2018/preds/"
selectionPath = "~/Documents/OrganizedScripts/SAT2018/selection/"
finalSelectionPath = "~/Documents/OrganizedScripts/SAT2018/final/"
modelPath = "~/Documents/mlr-scripts/SAT2018/Prediction/standardError/"
CVsetsPath = "~/Documents/OrganizedScripts/SAT2018/model_cv_all_sets/"
mcp_results_path = "~/Documents/OrganizedScripts/SAT2018/"
train_randomForest_validation_setPath = "~/Documents/mlr-scripts/SAT2018/Prediction/standardError_validation/"
#preds_path = "~/Documents/OrganizedScripts/SAT2018/preds_valid/"
#preds_path_valid = "~/Documents/OrganizedScripts/SAT2018/preds_valid/validation/"
selection_valid_path = "~/Documents/OrganizedScripts/SAT2018/preds_valid/validation/selection/"
selection_valid_exptected_path = "~/Documents/OrganizedScripts/SAT2018/preds_valid/validation/selectionExpected/"
expected_pred_path =  "~/Documents/OrganizedScripts/SAT2018/preds_valid/validation/expectedValues/"
actual_overhead_per_solverPath = "~/Documents/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc"
} else{
source("/gscratch/hkashgar/OrganizedScripts/OverheadResults.R")
Estimate_overhead_on_predictionPath ="/gscratch/hkashgar/OrganizedScripts/SAT2018/Estimate_overhead_on_prediction/"
actual_overhead_per_solverPlotPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc/plot/"
actual_overhead_per_solverPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc/"
actual_overhead_per_corePlotPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/actual_overhead_per_core_perc/plot/"
actual_overhead_per_corePath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/actual_overhead_per_core_perc/"
#predictionPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/preds/"
selectionPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/selection/"
finalSelectionPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/final/"
modelPath = "/gscratch/hkashgar/mlr-scripts/SAT2018/Prediction/standardError/"
CVsetsPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/model_cv_all_sets/"
mcp_results_path = "/gscratch/hkashgar/OrganizedScripts/SAT2018/"
train_randomForest_validation_setPath = "/gscratch/hkashgar/mlr-scripts/SAT2018/Prediction/standardError_validation/"
#preds_path = "/gscratch/hkashgar/OrganizedScripts/SAT2018/preds_valid/"
#preds_path_valid = "/gscratch/hkashgar/OrganizedScripts/SAT2018/preds_valid/validation/"
selection_valid_path = "/gscratch/hkashgar/OrganizedScripts/SAT2018/preds_valid/validation/selection/"
selection_valid_exptected_path = "/gscratch/hkashgar/OrganizedScripts/SAT2018/preds_valid/validation/selectionExpected/"
expected_pred_path =  "/gscratch/hkashgar/OrganizedScripts/SAT2018/preds_valid/validation/expectedValues/"
actual_overhead_per_solverPath = "/gscratch/hkashgar/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc"
}
} else{
source("C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/OverheadResults.R")
Estimate_overhead_on_predictionPath ="C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/Estimate_overhead_on_prediction/"
actual_overhead_per_solverPlotPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc/plot/"
actual_overhead_per_solverPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc/"
actual_overhead_per_corePlotPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/actual_overhead_per_core_perc/plot/"
actual_overhead_per_corePath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/actual_overhead_per_core_perc/"
#predictionPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/preds/"
selectionPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/selection/"
finalSelectionPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/final/"
#modelPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/mlr-scripts/Prediction/SAT2018/StandardError/"
CVsetsPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/model_cv_all_sets/"
mcp_results_path = "C:/Users/hnyk9/OneDrive - University of Wyoming/OrganizedScripts/SAT2018/"
train_randomForest_validation_setPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/mlr-scripts/SAT2018/Prediction/standardError_validation/"
#preds_path = "C:/Users/hnyk9/OneDrive - University of Wyoming/Documents/OrganizedScripts/SAT2018/preds_valid/"
#preds_path_valid = "C:/Users/hnyk9/OneDrive - University of Wyoming/Documents/OrganizedScripts/SAT2018/preds_valid/validation/"
selection_valid_path = "C:/Users/hnyk9/OneDrive - University of Wyoming/Documents/OrganizedScripts/SAT2018/preds_valid/validation/selection/"
selection_valid_exptected_path = "C:/Users/hnyk9/OneDrive - University of Wyoming/Documents/OrganizedScripts/SAT2018/preds_valid/validation/selectionExpected/"
expected_pred_path =  "C:/Users/hnyk9/OneDrive - University of Wyoming/Documents/OrganizedScripts/SAT2018/preds_valid/validation/expectedValues/"
actual_overhead_per_solverPath = "C:/Users/hnyk9/OneDrive - University of Wyoming/Documents/OrganizedScripts/SAT2018/actual_overhead_per_solver_perc"
}
# vbs
self = SequentialPerformance$new(benchmarks_name = "SAT2018")
vbs = self$get_VBS()
mean(vbs$VBS_Runtime)
median(vbs$VBS_Runtime)
vbs_par10 = self$get_VBS_par10()
mean(vbs_par10$VBS_Runtime)
median(vbs_par10$VBS_Runtime)
vbs_mcp = self$get_VBS_mcp()
vbs_success = sum(vbs$VBS_Runtime<5000)
vbs_success/nrow(vbs)*100
self = SequentialPerformance$new(benchmarks_name = "SAT2018")
range = c(1:10)
top_vbs = data.frame(matrix(nrow = nrow(vbs), ncol = 0))
top_vbs = cbind(top_vbs, vbs$InstanceName)
for(i in range){
par = ParallelLevel$new(benchmarks_name = "SAT2018", cores = i)
top_n_vbs = vector()
for(j in 1:i){
nd_vbs = par$get_nd_vbs_runtime(instanceset = vbs$InstanceName, ignore_instances = FALSE, nd = j)
top_n_vbs = cbind(top_n_vbs, nd_vbs$VBS_Runtime)
}
nd_vbs = rowMins(top_n_vbs)
top_vbs = cbind(top_vbs,nd_vbs)
}
colnames(top_vbs) = c("InstanceName", str_c(rep("cores_",10), c(1:10)))
write.csv(top_vbs, "~/Documents/OrganizedScripts/results/SAT2018/top_vbs.csv", row.names = FALSE)
setwd("~/Documents/OrganizedScripts/results/SAT2018/")
library(reshape2)
top_vbs = read.csv("top_vbs.csv")
top_vbs[2:11] = apply(top_vbs[2:11],2,as.numeric)
#
sd = apply(top_vbs[2:11],2,sd)
mean = apply(top_vbs[2:11],2,mean)
median = apply(top_vbs[2:11],2,median)
sum_top_vbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_vbs$cores = c(1:10)
sum_top_vbs = sum_top_vbs[which(!(sum_top_vbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_vbs, aes(x=cores, y=mean,colour="Mean VBS Runtime")) +
geom_point()+
geom_point(aes(y=median,colour="Median VBS Runtime"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "Runtime"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
getwd()
ggsave(dpi = 500, width = 7, height = 5, filename = "VBS_behavior_different_cores_runtime.pdf")
top_sbs = read.csv("top_sbs.csv")
top_sbs[2:11] = apply(top_sbs[2:11],2,as.numeric)
sd = apply(top_sbs[2:11],2,sd)
mean = apply(top_sbs[2:11],2,mean)
median = apply(top_sbs[2:11],2,median)
sum_top_sbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_sbs$cores = c(1:10)
sum_top_sbs = sum_top_sbs[which(!(sum_top_sbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_sbs, aes(x=cores, y=mean,colour="Mean SBS Runtime")) +
geom_point()+
geom_point(aes(y=median,colour="Median SBS Runtime"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "Runtime"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
ggsave(filename = "SBS_behavior_different_cores_runtime.pdf",dpi = 500, width = 7, height = 5)
results = data.frame(matrix(nrow= 0, ncol=4))
approaches = c("Single Best Solver", "Virtual Best Solver", "ASPEED",
"AS_0", "AS_theta")
for(approach in approaches){
sub_df = data.frame(matrix(nrow= 10, ncol=0))
sub_df$Cores = c(1:10)
sub_df$Approach = approach
if(approach == "Virtual Best Solver"){
sub_df$Mean = as.numeric(sum_top_vbs$mean)
sub_df$Median = as.numeric(sum_top_vbs$median)
} else if(approach == "Single Best Solver"){
sub_df$Mean = as.numeric(sum_top_sbs$mean)
sub_df$Median = as.numeric(sum_top_sbs$median)
} else if(approach == "ASPEED"){
means = vector()
medians = vector()
saveCsv = data.frame(matrix(nrow = 353, ncol=0))
for(c in sub_df$Cores){
csv = read.csv(paste("~/Documents/OrganizedScripts/results/aspeed_3folds_parallelTestFile/SAT2018/SAT2018_",c,"cores_print.error",sep=""))
aspeed = csv$ASP
saveCsv[paste("cores_",c,sep="")] = aspeed
means = append(means, mean(aspeed))
medians = append(medians, median(aspeed))
}
write.csv(saveCsv,"top_aspeed.csv", row.names = FALSE)
sub_df$Mean = as.numeric(means)
sub_df$Median = as.numeric(medians)
} else if(approach == "AS_0"){
means = vector()
medians = vector()
saveCsv = data.frame(matrix(nrow = 353, ncol=0))
for(c in sub_df$Cores){
runtimes = vector()
path = paste("~/Documents/OrganizedScripts/results/SAT2018/selections_algorithmSelection_noUncertainty/",c,"_cores/",sep="")
csvs = list.files(path,".csv")
for(csv in csvs){
df = read.csv(paste(path,csv,sep=""))
runtime = min(df$ParallelRuntime)
runtimes = append(runtimes,runtime)
}
saveCsv[paste("cores_",c,sep="")] = runtimes
means = append(means, mean(runtimes))
medians = append(medians, median(runtimes))
}
write.csv(saveCsv,"top_as_0.csv", row.names = FALSE)
sub_df$Mean = as.numeric(means)
sub_df$Median = as.numeric(medians)
} else if(approach == "AS_theta"){
means = vector()
medians = vector()
saveCsv = data.frame(matrix(nrow = 353, ncol=0))
for(c in sub_df$Cores){
runtimes = vector()
path = paste("~/Documents/OrganizedScripts/results/SAT2018/selections_optimal_theta/selection_optimal_theta_",c,"_cores/",sep="")
csvs = list.files(path,".csv")
for(csv in csvs){
df = read.csv(paste(path,csv,sep=""))
runtime = min(df$ParallelRuntime)
runtimes = append(runtimes,runtime)
}
saveCsv[paste("cores_",c,sep="")] = runtimes
means = append(means, mean(runtimes))
medians = append(medians, median(runtimes))
}
write.csv(saveCsv,"top_as_theta.csv", row.names = FALSE)
sub_df$Mean = as.numeric(means)
sub_df$Median = as.numeric(medians)
}
results = rbind(results,sub_df)
}
results$Mean = as.numeric(results$Mean)
results$Median = as.numeric(results$Median)
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "Runtime (s)", title = "SAT2018")+
scale_x_continuous(breaks=c(1:10))
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "Runtime (s)", title = "SAT2018")+theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:10))
ggsave(dpi = 500, width = 9, height = 5, filename = "SAT18_line_chart_parallel_runtime.pdf")
#MCP
setwd("~/Documents/OrganizedScripts/results/SAT2018/")
library(reshape2)
top_vbs = read.csv("top_vbs_mcp.csv")
top_vbs[1:10] = apply(top_vbs[1:10],2,as.numeric)
sd = apply(top_vbs[1:10],2,sd)
mean = apply(top_vbs[1:10],2,mean)
median = apply(top_vbs[1:10],2,median)
sum_top_vbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_vbs$cores = c(1:10)
sum_top_vbs = sum_top_vbs[which(!(sum_top_vbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_vbs, aes(x=cores, y=mean,colour="Mean VBS MCP")) +
geom_point()+
geom_point(aes(y=median,colour="Median VBS MCP"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "MCP"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
getwd()
ggsave(dpi = 500, width = 7, height = 5, filename = "VBS_behavior_different_cores_MCP.pdf")
top_sbs = read.csv("top_sbs_mcp.csv")
top_sbs[1:10] = apply(top_sbs[1:10],2,as.numeric)
sd = apply(top_sbs[1:10],2,sd)
mean = apply(top_sbs[1:10],2,mean)
median = apply(top_sbs[1:10],2,median)
sum_top_sbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_sbs$cores = c(1:10)
sum_top_sbs = sum_top_sbs[which(!(sum_top_sbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_sbs, aes(x=cores, y=mean,colour="Mean SBS MCP")) +
geom_point()+
geom_point(aes(y=median,colour="Median SBS MCP"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "MCP"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
ggsave(filename = "SBS_behavior_different_cores_MCP.pdf",dpi = 500, width = 7, height = 5)
results = data.frame(matrix(nrow= 0, ncol=4))
approaches = c("Single Best Solver", "Virtual Best Solver", "ASPEED",
"AS_0", "AS_theta")
for(approach in approaches){
sub_df = data.frame(matrix(nrow= 10, ncol=0))
sub_df$Cores = c(1:10)
sub_df$Approach = approach
if(approach == "Virtual Best Solver"){
sub_df$Mean = as.numeric(sum_top_vbs$mean)
sub_df$Median = as.numeric(sum_top_vbs$median)
} else if(approach == "Single Best Solver"){
sub_df$Mean = as.numeric(sum_top_sbs$mean)
sub_df$Median = as.numeric(sum_top_sbs$median)
} else if(approach == "ASPEED"){
aspeed = read.csv("top_aspeed_mcp.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(aspeed)))
sub_df$Median = as.numeric(colMedians(as.matrix(aspeed)))
} else if(approach == "AS_0"){
as_0 = read.csv("top_as_0_mcp.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(as_0)))
sub_df$Median = as.numeric(colMedians(as.matrix(as_0)))
} else if(approach == "AS_theta"){
as_0 = read.csv("top_as_theta_mcp.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(as_0)))
sub_df$Median = as.numeric(colMedians(as.matrix(as_0)))
}
results = rbind(results,sub_df)
}
results$Mean = as.numeric(results$Mean)
results$Median = as.numeric(results$Median)
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "MCP (s)", title = "SAT2018")+scale_x_continuous(breaks=c(1:10))+theme(plot.title = element_text(hjust = 0.5))+
ggsave(dpi = 500, width = 9, height = 5, filename = "SAT18_line_chart_parallel_MCP.pdf")
#Par10
setwd("~/Documents/OrganizedScripts/results/SAT2018/")
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "MCP (s)", title = "SAT2018")+scale_x_continuous(breaks=c(1:10))+theme(plot.title = element_text(hjust = 0.5))+
ggsave(dpi = 500, width = 9, height = 5, filename = "SAT18_line_chart_parallel_MCP.pdf")
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "MCP (s)", title = "SAT2018")+theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(breaks=c(1:10))
ggsave(dpi = 500, width = 9, height = 5, filename = "SAT18_line_chart_parallel_MCP.pdf")
#Par10
setwd("~/Documents/OrganizedScripts/results/SAT2018/")
library(reshape2)
top_vbs = read.csv("top_vbs_par10.csv")
top_vbs[1:10] = apply(top_vbs[1:10],2,as.numeric)
sd = apply(top_vbs[1:10],2,sd)
mean = apply(top_vbs[1:10],2,mean)
median = apply(top_vbs[1:10],2,median)
sum_top_vbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_vbs$cores = c(1:10)
sum_top_vbs = sum_top_vbs[which(!(sum_top_vbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_vbs, aes(x=cores, y=mean,colour="Mean VBS PAR10")) +
geom_point()+
geom_point(aes(y=median,colour="Median VBS PAR10"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "PAR10"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
getwd()
ggsave(dpi = 500, width = 7, height = 5, filename = "VBS_behavior_different_cores_PAR10.pdf")
top_sbs = read.csv("top_sbs_par10.csv")
top_sbs[1:10] = apply(top_sbs[1:10],2,as.numeric)
sd = apply(top_sbs[1:10],2,sd)
mean = apply(top_sbs[1:10],2,mean)
median = apply(top_sbs[1:10],2,median)
sum_top_sbs = data.frame(mean = mean, median = median, sd = sd)
sum_top_sbs$cores = c(1:10)
sum_top_sbs = sum_top_sbs[which(!(sum_top_sbs$cores%in% c(11:19,20:29,31, 33:38))),]
p<-ggplot(sum_top_sbs, aes(x=cores, y=mean,colour="Mean SBS PAR10")) +
geom_point()+
geom_point(aes(y=median,colour="Median SBS PAR10"))+
geom_errorbar(aes(ymin=mean-sd,
ymax=mean+sd), width=.2,
position=position_dodge(0.05))+
scale_y_continuous(
name = "PAR10"
#sec.axis = sec_axis( trans=~./self$Cutoff , name="probability of solving instance RegRF prediction")
)
p
ggsave(filename = "SBS_behavior_different_cores_PAR10.pdf",dpi = 500, width = 7, height = 5)
results = data.frame(matrix(nrow= 0, ncol=4))
approaches = c("Single Best Solver", "Virtual Best Solver", "ASPEED",
"AS_0", "AS_theta")
for(approach in approaches){
sub_df = data.frame(matrix(nrow= 10, ncol=0))
sub_df$Cores = c(1:10)
sub_df$Approach = approach
if(approach == "Virtual Best Solver"){
sub_df$Mean = as.numeric(sum_top_vbs$mean)
sub_df$Median = as.numeric(sum_top_vbs$median)
} else if(approach == "Single Best Solver"){
sub_df$Mean = as.numeric(sum_top_sbs$mean)
sub_df$Median = as.numeric(sum_top_sbs$median)
} else if(approach == "ASPEED"){
aspeed = read.csv("top_aspeed_par10.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(aspeed)))
sub_df$Median = as.numeric(colMedians(as.matrix(aspeed)))
} else if(approach == "AS_0"){
as_0 = read.csv("top_as_0_par10.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(as_0)))
sub_df$Median = as.numeric(colMedians(as.matrix(as_0)))
} else if(approach == "AS_theta"){
as_0 = read.csv("top_as_theta_par10.csv")
sub_df$Mean = as.numeric(colMeans(as.matrix(as_0)))
sub_df$Median = as.numeric(colMedians(as.matrix(as_0)))
}
results = rbind(results,sub_df)
}
results$Mean = as.numeric(results$Mean)
results$Median = as.numeric(results$Median)
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "PAR10 (s)")+scale_x_continuous(breaks = c(1:10))+theme(plot.title = element_text(hjust = 0.5))
ggplot(results, aes(x=Cores, y=Mean, colour = Approach, shape = Approach)) +
geom_point(size = 3)+
geom_line(aes(linetype="Mean"), size = 1)+
geom_point(aes(y=Median),size = 3)+
geom_line(aes(y = Median, linetype = "Median"), size = 1)+
guides(linetype=guide_legend(title="",keywidth = 3, keyheight = 1.5),
colour = guide_legend(keywidth = 3, keyheight = 1.5))+
expand_limits(x = 1, y = 0)+ theme(text=element_text(size=22,  family="Times"))+
labs(x = "Cores", y = "PAR10 (s)",title = "SAT2018")+scale_x_continuous(breaks = c(1:10))+theme(plot.title = element_text(hjust = 0.5))
ggsave(dpi = 500, width = 9, height = 5, filename = "SAT18_line_chart_parallel_PAR10.pdf")
